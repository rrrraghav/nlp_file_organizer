{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50761442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def process_image_ocr(image_path):\n",
    "    \n",
    "    text = pytesseract.image_to_string(Image.open(image_path))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0eb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "MODEL = \"google/gemma-3-12b\"\n",
    "\n",
    "def process_image_llm(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        base64_image = base64.b64encode(f.read()).decode()\n",
    "\n",
    "    prompt = \"Extract all text from this image exactly as it appears. Output only the raw text with no formatting, \" \\\n",
    "             \"no explanations, no markdown, no bullet points. Preserve the original spacing and line breaks. \" \\\n",
    "             \"Pay close attention to spelling. Transcribe every word character-by-character exactly as shown, \" \\\n",
    "             \"including unusual spellings or names. Do not autocorrect or fix anything.\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "            ]\n",
    "        }],\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    response = requests.post(BASE_URL, json=payload)\n",
    "    return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19341fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Mossago-~\n",
      "\n",
      "From: Bugg, Joy J.\n",
      "\n",
      "Sent: 14 avril 2000 21:02\n",
      "\n",
      "To: Solana, Rick P.;Patskan, George J. Walk, Roger A. Sanders, Edward; Davies, Bruce D; McAlpin, Loreen;\n",
      "King, Valerie A.\n",
      "\n",
      "Ge: Cash, Fldse B.; Putney, Rebecca M.; Gygax, Jil; Mawyer, Denise T.\n",
      "\n",
      "Subject: FW: Updated OBT Matrix\n",
      "\n",
      "VEOPTOSSOST\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "230592403A\n",
      "\n",
      "Original Message\n",
      "From: Bugg, Joy J.\n",
      "Sent: 14 avril 2000 21:02\n",
      "To: Solano, Rick P.; Patskan, George J.; Sanders, Edward; Davies, Bruce D.; McAlpin, Loreen;\n",
      "\tKing, Valerie A.\n",
      "Cc: Cash, Rose B.; Putney, Rebecca M.; Gygax, Jill; Mawyer, Denise T.\n",
      "Subject: FW: Updated OBT Matrix\n"
     ]
    }
   ],
   "source": [
    "# testing with good quality file (email)\n",
    "ocr_result = process_image_ocr(\"docs-sm/email/2505592403a.jpg\")\n",
    "llm_result = process_image_llm(\"docs-sm/email/2505592403a.jpg\")\n",
    "\n",
    "print(ocr_result)\n",
    "print(\"--------------------\\n\")\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5af3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\n",
      "FREE SAMPLE\n",
      "\n",
      "FREE SAMPLE\n",
      "\n",
      "Warning: The Surgeon General Has Determined \n",
      "The Cigarette Smoking is Dangerous to Your Health.\n",
      "\n",
      "RL-SC-83-25\n",
      "DATE 4/16/79\n",
      "RALEIGH\n",
      "LIGHTS\n",
      "\n",
      "RALEIGH\n",
      "LIGHTS 8 mg. \"Tar\", 0.7 mg nicotine\n",
      "Approximate values. Vary by brand.\n",
      "\n",
      "eas 4/20/79\n",
      "\n",
      "670127085\n"
     ]
    }
   ],
   "source": [
    "# testing with poor quality file (old advertisement)\n",
    "unclear_ocr_result = process_image_ocr(\"docs-sm/advertisement/0000126151.jpg\")\n",
    "unclear_llm_result = process_image_llm(\"docs-sm/advertisement/0000126151.jpg\")\n",
    "\n",
    "#print(unclear_ocr_result)\n",
    "print(\"--------------------\\n\")\n",
    "print(unclear_llm_result)\n",
    "\n",
    "# clearly typical OCR does not work for our dataset\n",
    "# even if vision model is not perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23585a0b",
   "metadata": {},
   "source": [
    "# Note on model pick - future iteration\n",
    "On low quality images the 12b model is very inconsistent in producing good results, although way better than any OCR based approach we have tested. For future parts of project we might want to spend time rerunning pipeline with 27b model as it produced better results but also considerable amount more of runtime so for check-in we leave it for 12b to finish first iteration of project and see how our models like LR perform on this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
